"""
Dataset í´ë” ë¶„ë¥˜ ë° ë¶„ì„ ë„êµ¬
ë¬¸ì„œ, ì´ë¯¸ì§€, ë…¼ë¬¸ ë“±ì„ ìë™ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³  ë¶„ì„
"""

import os
from pathlib import Path
from typing import Dict, List, Tuple
from datetime import datetime
import json
import shutil

class DatasetAnalyzer:
    """Dataset í´ë” ë¶„ì„ ë° ë¶„ë¥˜"""
    
    def __init__(self, dataset_path: str):
        self.dataset_path = Path(dataset_path)
        self.analysis_results = {
            'scan_time': datetime.now().isoformat(),
            'total_files': 0,
            'total_directories': 0,
            'file_categories': {},
            'directory_structure': {},
            'large_files': [],
            'important_documents': [],
            'images': [],
            'research_papers': []
        }
    
    def scan_directory(self) -> Dict:
        """ë””ë ‰í† ë¦¬ ì „ì²´ ìŠ¤ìº”"""
        print(f"ğŸ“‚ ìŠ¤ìº” ì‹œì‘: {self.dataset_path}")
        
        for root, dirs, files in os.walk(self.dataset_path):
            self.analysis_results['total_directories'] += len(dirs)
            
            for file in files:
                file_path = Path(root) / file
                self._analyze_file(file_path)
                self.analysis_results['total_files'] += 1
        
        self._generate_statistics()
        return self.analysis_results
    
    def _analyze_file(self, file_path: Path):
        """ê°œë³„ íŒŒì¼ ë¶„ì„"""
        try:
            file_info = {
                'name': file_path.name,
                'path': str(file_path.relative_to(self.dataset_path)),
                'size_mb': file_path.stat().st_size / (1024 * 1024),
                'extension': file_path.suffix.lower(),
                'category': self._categorize_file(file_path)
            }
            
            # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
            category = file_info['category']
            if category not in self.analysis_results['file_categories']:
                self.analysis_results['file_categories'][category] = []
            self.analysis_results['file_categories'][category].append(file_info)
            
            # í° íŒŒì¼ (10MB ì´ìƒ)
            if file_info['size_mb'] > 10:
                self.analysis_results['large_files'].append(file_info)
            
            # ì¤‘ìš” ë¬¸ì„œ
            if self._is_important_document(file_path):
                self.analysis_results['important_documents'].append(file_info)
            
            # ì´ë¯¸ì§€
            if category == 'images':
                self.analysis_results['images'].append(file_info)
            
            # ë…¼ë¬¸
            if category == 'papers':
                self.analysis_results['research_papers'].append(file_info)
                
        except Exception as e:
            print(f"âš ï¸ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {file_path.name} - {e}")
    
    def _categorize_file(self, file_path: Path) -> str:
        """íŒŒì¼ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        ext = file_path.suffix.lower()
        name = file_path.name.lower()
        
        # ë¬¸ì„œ
        if ext in ['.pdf', '.docx', '.doc', '.txt', '.md']:
            if any(keyword in name for keyword in ['ë…¼ë¬¸', 'paper', 'article']):
                return 'papers'
            elif any(keyword in name for keyword in ['ë³´ê³ ì„œ', 'report', 'ë¶„ì„']):
                return 'reports'
            else:
                return 'documents'
        
        # ì´ë¯¸ì§€
        elif ext in ['.png', '.jpg', '.jpeg', '.tif', '.tiff', '.bmp']:
            if any(keyword in name for keyword in ['ì•”', 'cancer', 'cell', 'hct', 'snu']):
                return 'cell_images'
            return 'images'
        
        # í”„ë ˆì  í…Œì´ì…˜
        elif ext in ['.pptx', '.ppt']:
            return 'presentations'
        
        # ë°ì´í„°
        elif ext in ['.csv', '.xlsx', '.xls', '.json']:
            return 'data_files'
        
        else:
            return 'others'
    
    def _is_important_document(self, file_path: Path) -> bool:
        """ì¤‘ìš” ë¬¸ì„œ íŒë³„"""
        name = file_path.name.lower()
        keywords = [
            'ê³„íšì„œ', 'ë³´ê³ ì„œ', 'íŠ¹í—ˆ', 'patent',
            'ë…¼ë¬¸', 'paper', 'article',
            'ì—°êµ¬', 'research', 'ë¶„ì„', 'analysis',
            'comprehensive', 'report', 'final'
        ]
        return any(keyword in name for keyword in keywords)
    
    def _generate_statistics(self):
        """í†µê³„ ìƒì„±"""
        # ì¹´í…Œê³ ë¦¬ë³„ íŒŒì¼ ê°œìˆ˜
        category_counts = {
            cat: len(files) 
            for cat, files in self.analysis_results['file_categories'].items()
        }
        self.analysis_results['category_statistics'] = category_counts
        
        # ì´ë¯¸ì§€ í†µê³„
        total_images = len(self.analysis_results['images'])
        cell_images = len([
            f for f in self.analysis_results['images'] 
            if 'cell' in f['category']
        ])
        self.analysis_results['image_statistics'] = {
            'total': total_images,
            'cell_images': cell_images,
            'other_images': total_images - cell_images
        }
    
    def organize_by_category(self, output_dir: str = None):
        """ì¹´í…Œê³ ë¦¬ë³„ë¡œ íŒŒì¼ ì •ë¦¬ (ë³µì‚¬)"""
        if output_dir is None:
            output_dir = self.dataset_path.parent / 'dataset_organized'
        
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        print(f"\nğŸ“ íŒŒì¼ ì •ë¦¬ ì‹œì‘: {output_dir}")
        
        organized_count = 0
        for category, files in self.analysis_results['file_categories'].items():
            category_dir = output_dir / category
            category_dir.mkdir(exist_ok=True)
            
            for file_info in files:
                source = self.dataset_path / file_info['path']
                dest = category_dir / file_info['name']
                
                try:
                    # ì¤‘ë³µ íŒŒì¼ëª… ì²˜ë¦¬
                    if dest.exists():
                        base = dest.stem
                        ext = dest.suffix
                        counter = 1
                        while dest.exists():
                            dest = category_dir / f"{base}_{counter}{ext}"
                            counter += 1
                    
                    shutil.copy2(source, dest)
                    organized_count += 1
                except Exception as e:
                    print(f"âš ï¸ ë³µì‚¬ ì‹¤íŒ¨: {file_info['name']} - {e}")
        
        print(f"âœ… {organized_count}ê°œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ!")
        return output_dir
    
    def generate_report(self, output_file: str = None) -> str:
        """ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        if output_file is None:
            output_file = self.dataset_path.parent / f'dataset_analysis_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.md'
        
        report = self._create_markdown_report()
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"\nğŸ“„ ë³´ê³ ì„œ ìƒì„±: {output_file}")
        return str(output_file)
    
    def _create_markdown_report(self) -> str:
        """ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±"""
        results = self.analysis_results
        
        report = f"""# Dataset í´ë” ë¶„ì„ ë³´ê³ ì„œ

## ğŸ“Š ê¸°ë³¸ ì •ë³´

- **ìŠ¤ìº” ì‹œê°„**: {results['scan_time']}
- **ìŠ¤ìº” ê²½ë¡œ**: {self.dataset_path}
- **ì´ íŒŒì¼ ìˆ˜**: {results['total_files']}ê°œ
- **ì´ ë””ë ‰í† ë¦¬ ìˆ˜**: {results['total_directories']}ê°œ

---

## ğŸ“ ì¹´í…Œê³ ë¦¬ë³„ íŒŒì¼ ë¶„ë¥˜

"""
        
        # ì¹´í…Œê³ ë¦¬ í†µê³„
        for category, count in sorted(results.get('category_statistics', {}).items(), key=lambda x: x[1], reverse=True):
            category_names = {
                'papers': 'ğŸ“š ë…¼ë¬¸',
                'reports': 'ğŸ“‹ ë³´ê³ ì„œ',
                'documents': 'ğŸ“„ ë¬¸ì„œ',
                'cell_images': 'ğŸ”¬ ì„¸í¬ ì´ë¯¸ì§€',
                'images': 'ğŸ–¼ï¸ ì´ë¯¸ì§€',
                'presentations': 'ğŸ“Š í”„ë ˆì  í…Œì´ì…˜',
                'data_files': 'ğŸ“ˆ ë°ì´í„° íŒŒì¼',
                'others': 'ğŸ“¦ ê¸°íƒ€'
            }
            name = category_names.get(category, category)
            report += f"- **{name}**: {count}ê°œ\n"
        
        report += "\n---\n\n## ğŸ” ì¤‘ìš” ë¬¸ì„œ\n\n"
        
        for doc in results['important_documents'][:20]:  # ìƒìœ„ 20ê°œ
            report += f"- **{doc['name']}**\n"
            report += f"  - ê²½ë¡œ: `{doc['path']}`\n"
            report += f"  - í¬ê¸°: {doc['size_mb']:.2f} MB\n\n"
        
        report += f"\nì „ì²´ {len(results['important_documents'])}ê°œ\n\n"
        report += "---\n\n## ğŸ”¬ ì„¸í¬ ì´ë¯¸ì§€\n\n"
        
        cell_images = [f for f in results['images'] if f['category'] == 'cell_images']
        report += f"**ì´ {len(cell_images)}ê°œì˜ ì„¸í¬ ì´ë¯¸ì§€ ë°œê²¬**\n\n"
        
        # ë””ë ‰í† ë¦¬ë³„ ê·¸ë£¹í™”
        image_dirs = {}
        for img in cell_images:
            dir_name = Path(img['path']).parent
            if dir_name not in image_dirs:
                image_dirs[dir_name] = []
            image_dirs[dir_name].append(img)
        
        for dir_name, images in sorted(image_dirs.items()):
            report += f"### {dir_name}\n\n"
            report += f"- ì´ë¯¸ì§€ ìˆ˜: {len(images)}ê°œ\n"
            report += f"- ì´ í¬ê¸°: {sum(img['size_mb'] for img in images):.2f} MB\n\n"
        
        report += "\n---\n\n## ğŸ“š ì—°êµ¬ ë…¼ë¬¸\n\n"
        
        for paper in results['research_papers'][:15]:
            report += f"- **{paper['name']}**\n"
            report += f"  - ê²½ë¡œ: `{paper['path']}`\n"
            report += f"  - í¬ê¸°: {paper['size_mb']:.2f} MB\n\n"
        
        report += "\n---\n\n## ğŸ’¾ ëŒ€ìš©ëŸ‰ íŒŒì¼ (10MB ì´ìƒ)\n\n"
        
        large_files = sorted(results['large_files'], key=lambda x: x['size_mb'], reverse=True)
        for file in large_files[:10]:
            report += f"- **{file['name']}** ({file['size_mb']:.1f} MB)\n"
            report += f"  - ê²½ë¡œ: `{file['path']}`\n\n"
        
        report += "\n---\n\n## ğŸ“ˆ ë¶„ë¥˜ ì œì•ˆ\n\n"
        report += "### ì •ë¦¬ ìš°ì„ ìˆœìœ„\n\n"
        report += "1. **ë…¼ë¬¸ ë° ë³´ê³ ì„œ** â†’ `ë…¼ë¬¸` í´ë”ë¡œ í†µí•©\n"
        report += "2. **ì„¸í¬ ì´ë¯¸ì§€** â†’ `ì„¸í¬ì´ë¯¸ì§€` í´ë”ë¡œ ì •ë¦¬\n"
        report += "3. **í”„ë ˆì  í…Œì´ì…˜** â†’ `ë°œí‘œìë£Œ` í´ë”ë¡œ ì´ë™\n"
        report += "4. **ë°ì´í„° íŒŒì¼** â†’ `data` í´ë”ë¡œ í†µí•©\n\n"
        
        report += "---\n\n"
        report += f"*ë³´ê³ ì„œ ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
        
        return report
    
    def save_json(self, output_file: str = None):
        """JSONìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        if output_file is None:
            output_file = self.dataset_path.parent / 'dataset_analysis.json'
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ JSON ì €ì¥: {output_file}")
        return str(output_file)


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    import sys
    
    # Dataset ê²½ë¡œ
    if len(sys.argv) > 1:
        dataset_path = sys.argv[1]
    else:
        dataset_path = Path(__file__).parent.parent / 'dataset'
    
    print("=" * 60)
    print("ğŸ“‚ Dataset í´ë” ë¶„ë¥˜ ë° ë¶„ì„ ë„êµ¬")
    print("=" * 60)
    print()
    
    # ë¶„ì„ê¸° ìƒì„±
    analyzer = DatasetAnalyzer(dataset_path)
    
    # ìŠ¤ìº” ì‹¤í–‰
    results = analyzer.scan_directory()
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ“Š ë¶„ì„ ì™„ë£Œ!")
    print("=" * 60)
    print(f"ì´ íŒŒì¼: {results['total_files']}ê°œ")
    print(f"ì´ ë””ë ‰í† ë¦¬: {results['total_directories']}ê°œ")
    print()
    print("ì¹´í…Œê³ ë¦¬ë³„ íŒŒì¼ ìˆ˜:")
    for cat, count in sorted(results.get('category_statistics', {}).items(), key=lambda x: x[1], reverse=True):
        print(f"  - {cat}: {count}ê°œ")
    print()
    
    # ë³´ê³ ì„œ ìƒì„±
    report_file = analyzer.generate_report()
    
    # JSON ì €ì¥
    json_file = analyzer.save_json()
    
    # ì •ë¦¬ ì˜µì…˜
    print("\níŒŒì¼ ì •ë¦¬ë¥¼ í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end='')
    choice = input().strip().lower()
    
    if choice == 'y':
        organized_dir = analyzer.organize_by_category()
        print(f"\nâœ… íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: {organized_dir}")
    
    print("\n" + "=" * 60)
    print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print("=" * 60)


if __name__ == "__main__":
    main()
